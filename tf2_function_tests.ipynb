{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test some tensorflow 2 functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 ... 19999994 19999996 19999998]\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "number_elements = 1e7\n",
    "arr1 = np.arange(0,number_elements)\n",
    "arr2 = np.arange(0,number_elements)\n",
    "arr3 = tf.Variable(arr1)\n",
    "arr4 = tf.Variable(arr2)\n",
    "\n",
    "out1 = add(arr3, arr4)  \n",
    "tf.print(out1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function add: 0.1614471950015286\n"
     ]
    }
   ],
   "source": [
    "# I get usaul values of Function add: 0.1712134879999212 on a txGPU\n",
    "print(\"Function add:\", timeit.timeit(lambda: add(arr3, arr4) , number=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU or CPU version of tensorflow is being used.\n",
    "import tensorflow as tf \n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"CPU version of TF s being used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python side effects like printing, appending to lists, and mutating globals only happen the first time you call a Function with a set of inputs. Afterwards, the traced tf.Graph is reexecuted, without executing the Python code.\n",
    "\n",
    "The general rule of thumb is to only use Python side effects to debug your traces. Otherwise, TensorFlow ops like tf.Variable.assign, tf.print, and tf.summary are the best way to ensure your code will be traced and executed by the TensorFlow runtime with each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 1\n",
      "Executed with 1\n",
      "Executed with 1\n",
      "Traced with 2\n",
      "Executed with 2\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  print(\"Traced with\", x)\n",
    "  tf.print(\"Executed with\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple loop\n",
    "\n",
    "AutoGraph Transformations\n",
    "AutoGraph is a library that is on by default in tf.function, and transforms a subset of Python eager code into graph-compatible TensorFlow ops. This includes control flow like if, for, while.\n",
    "\n",
    "TensorFlow ops like tf.cond and tf.while_loop continue to work, but control flow is often easier to write and understand when written in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.565189481 0.887629271 0.743468642 0.961964488 0.515973687]\n",
      "[0.511817575 0.710220814 0.631236255 0.745151877 0.474586517]\n",
      "[0.471360147 0.610815287 0.55890286 0.632247686 0.44189769]\n",
      "[0.439297646 0.544700742 0.507162929 0.559597969 0.415216208]\n",
      "[0.413062096 0.496538 0.467731744 0.507679105 0.392892718]\n",
      "[0.391069591 0.459390134 0.4363648 0.46813488 0.373851329]\n",
      "[0.372281939 0.429587036 0.410626709 0.436691105 0.357355833]\n",
      "[0.355986089 0.40497613 0.389004678 0.41089797 0.342882842]\n",
      "[0.341673583 0.384198666 0.370501846 0.389234871 0.330048621]\n",
      "[0.328970671 0.366348207 0.354430586 0.370700419 0.318564445]\n",
      "[0.317595571 0.350793391 0.340298951 0.354604214 0.308208287]\n",
      "[0.307331204 0.337078959 0.327744246 0.340452462 0.29880622]\n",
      "[0.29800725 0.3248671 0.316492409 0.327881277 0.290219754]\n",
      "[0.289487898 0.313901126 0.306331903 0.316615701 0.28233704]\n",
      "[0.281663388 0.3039819 0.297096401 0.306443602 0.275066674]\n",
      "[0.274443865 0.294952333 0.288653165 0.297198236 0.268333048]\n",
      "[0.267755 0.28668654 0.280894697 0.288746506 0.26207304]\n",
      "[0.261534631 0.279082239 0.27373293 0.280980676 0.256233484]\n",
      "[0.255730361 0.272055447 0.26709491 0.273812473 0.250769228]\n",
      "[0.250297666 0.265536398 0.260919571 0.26716876 0.245641604]\n",
      "[0.245198444 0.259466588 0.255155444 0.260988384 0.240817353]\n",
      "[0.240399852 0.253796548 0.249758705 0.255219758 0.236267626]\n",
      "[0.235873386 0.248484135 0.244691834 0.249819 0.231967285]\n",
      "[0.23159422 0.243493199 0.239922464 0.244748503 0.227894306]\n",
      "[0.227540582 0.238792494 0.235422507 0.23997587 0.224029288]\n",
      "[0.223693296 0.234354883 0.23116748 0.235472962 0.220355093]\n",
      "[0.220035389 0.23015666 0.227135897 0.231215239 0.21685648]\n",
      "[0.216551796 0.226177 0.223308817 0.227181196 0.213519886]\n",
      "[0.213229075 0.222397551 0.219669491 0.223351866 0.210333154]\n",
      "[0.210055187 0.21880202 0.216203034 0.219710469 0.20728536]\n",
      "[0.207019329 0.215375945 0.212896138 0.21624209 0.204366684]\n",
      "[0.204111755 0.212106407 0.209736913 0.212933421 0.201568261]\n",
      "[0.201323673 0.208981797 0.206714675 0.209772557 0.198882028]\n",
      "[0.198647097 0.205991715 0.203819782 0.206748798 0.196300671]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.19607478, 0.20312674, 0.20104352, 0.20385249, 0.19381753],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "    do_return = False\n",
      "    retval_ = ag__.UndefinedReturnValue()\n",
      "    with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(loop_vars):\n",
      "            nonlocal x\n",
      "            (x,) = loop_vars\n",
      "\n",
      "        def loop_body():\n",
      "            nonlocal x\n",
      "            ag__.converted_call(tf.print, (x,), None, fscope)\n",
      "            x = ag__.converted_call(tf.tanh, (x,), None, fscope)\n",
      "\n",
      "        def loop_test():\n",
      "            return (ag__.converted_call(tf.reduce_sum, (x,), None, fscope) > 1)\n",
      "        ag__.while_stmt(loop_test, loop_body, get_state, set_state, ('x',), {})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = fscope.mark_return_value(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "    (do_return,)\n",
      "    return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#If you're curious you can inspect the code autograph generates.\n",
    "print(tf.autograph.to_code(f.python_function))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over Python data\n",
    "A common pitfall is to loop over Python/Numpy data within a tf.function. This loop will execute during the tracing process, adding a copy of your model to the tf.Graph for each iteration of the loop.\n",
    "\n",
    "If you want to wrap the entire training loop in tf.function, the safest way to do this is to wrap your data as a tf.data.Dataset so that AutoGraph will dynamically unroll the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train([(1, 1), (1, 1), (1, 1)]) contains 11 nodes in its graph\n",
      "train([(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]) contains 32 nodes in its graph\n",
      "train(<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 8 nodes in its graph\n",
      "train(<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 8 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def measure_graph_size(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "  loss = tf.constant(0)\n",
    "  for x, y in dataset:\n",
    "    loss += tf.abs(y - x) # Some dummy computation.\n",
    "  return loss\n",
    "\n",
    "small_data = [(1, 1)] * 3\n",
    "big_data = [(1, 1)] * 10\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wrapping Python/Numpy data in a Dataset, be mindful of tf.data.Dataset.from_generator versus tf.data.Dataset.from_tensors. The former will keep the data in Python and fetch it via tf.py_function which can have performance implications, whereas the latter will bundle a copy of the data as one large tf.constant() node in the graph, which can have memory implications.\n",
    "\n",
    "Reading data from files via TFRecordDataset/CsvDataset/etc. is the most effective way to consume data, as then TensorFlow itself can manage the asynchronous loading and prefetching of data, without having to involve Python. To learn more, see the tf.data guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulating values in a loop\n",
    "A common pattern is to accumulate intermediate values from a loop. Normally, this is accomplished by appending to a Python list or adding entries to a Python dictionary. However, as these are Python side effects, they will not work as expected in a dynamically unrolled loop. Use tf.TensorArray to accumulate results from a dynamically unrolled loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.98396146, 0.08971524, 0.11158168, 0.17933595],\n",
       "        [1.9246402 , 0.97155344, 0.20194113, 0.29107225],\n",
       "        [2.4606123 , 1.2398095 , 0.6950661 , 0.29418707]],\n",
       "\n",
       "       [[0.71156347, 0.5544238 , 0.27769125, 0.8710582 ],\n",
       "        [0.73514664, 1.0803417 , 1.0757699 , 1.0808052 ],\n",
       "        [1.2185955 , 1.086014  , 1.8058302 , 1.2472991 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "  return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "  max_seq_len = input_data.shape[0]\n",
    "\n",
    "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "  state = initial_state\n",
    "  for i in tf.range(max_seq_len):\n",
    "    state = rnn_step(input_data[i], state)\n",
    "    states = states.write(i, state)\n",
    "  return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
